{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aaa94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import gc\n",
    "from customed_pipeline import CustomedPipeline\n",
    "from hf import NewPhi3Config\n",
    "from safetensors import safe_open\n",
    "from model import CustomedPhi3ForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee492390",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [[\n",
    "    {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What about solving an 2x + 3 = 7 equation?\"},\n",
    "],\n",
    "[{\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"}]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c5f45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "model_id = \"microsoft/Phi-3-medium-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ea462eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "config = NewPhi3Config()\n",
    "model = CustomedPhi3ForCausalLM(config)\n",
    "pipe = CustomedPipeline(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf95b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomedPhi3ForCausalLM(\n",
      "  (norm): Phi3RMSNorm((5120,), eps=1e-06)\n",
      "  (lm_head): Linear(in_features=5120, out_features=32064, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bde2d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = pipe.preprocess(messages)\n",
    "outputs = pipe.forward(inputs)\n",
    "result = pipe.postprocess(outputs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24de32cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: \"/nas/user/hayoung/model-00001-of-00006.safetensors\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m failed_name \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m file_path \u001b[38;5;241m=\u001b[39m base_file_path_template\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m safe_open(file_path, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(f\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: \"/nas/user/hayoung/model-00001-of-00006.safetensors\""
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "외장 메모리에서 decoder layer [start,end)까지 가져오기 코드\n",
    "여기에 저장하기\n",
    "\"\"\"\n",
    "keys = []\n",
    "base_file_path_template = '/nas/user/hayoung/model-0000{}-of-00006.safetensors'\n",
    "base_key_name = \"model.layers.\"\n",
    "included_layers = ['.input_layernorm.weight','.mlp.down_proj.weight', '.mlp.gate_up_proj.weight',\n",
    "                   '.post_attention_layernorm.weight','.self_attn.o_proj.weight',\n",
    "                   '.self_attn.qkv_proj.weight']\n",
    "\n",
    "failed_name = []\n",
    "file_path = base_file_path_template.format(1)\n",
    "\n",
    "with safe_open(file_path, framework=\"pt\", device=\"cuda\") as f:\n",
    "    print(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8f66305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model.layers.10.input_layernorm.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_up_proj.weight', 'model.layers.10.post_attention_layernorm.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.qkv_proj.weight', 'model.layers.11.input_layernorm.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_up_proj.weight', 'model.layers.11.post_attention_layernorm.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.qkv_proj.weight', 'model.layers.12.input_layernorm.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_up_proj.weight', 'model.layers.12.post_attention_layernorm.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.qkv_proj.weight', 'model.layers.13.input_layernorm.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_up_proj.weight', 'model.layers.13.post_attention_layernorm.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.qkv_proj.weight', 'model.layers.6.input_layernorm.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.post_attention_layernorm.weight', 'model.layers.7.input_layernorm.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_up_proj.weight', 'model.layers.7.post_attention_layernorm.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.qkv_proj.weight', 'model.layers.8.input_layernorm.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_up_proj.weight', 'model.layers.8.post_attention_layernorm.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.qkv_proj.weight', 'model.layers.9.input_layernorm.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_up_proj.weight', 'model.layers.9.post_attention_layernorm.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.qkv_proj.weight']\n"
     ]
    }
   ],
   "source": [
    "file_path = base_file_path_template.format(2)\n",
    "\n",
    "with safe_open(file_path, framework=\"pt\", device=\"cuda\") as f:\n",
    "    print(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776c56ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Phi3Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ac8eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = Phi3Config.from_pretrained(\"microsoft/Phi-3-medium-4k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "690c44e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phi3Config {\n",
       "  \"_name_or_path\": \"Phi-3-medium-4k-instruct\",\n",
       "  \"architectures\": [\n",
       "    \"Phi3ForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"auto_map\": {\n",
       "    \"AutoConfig\": \"microsoft/Phi-3-medium-4k-instruct--configuration_phi3.Phi3Config\",\n",
       "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-medium-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
       "  },\n",
       "  \"bos_token_id\": 1,\n",
       "  \"embd_pdrop\": 0.0,\n",
       "  \"eos_token_id\": 32000,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 5120,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 17920,\n",
       "  \"max_position_embeddings\": 4096,\n",
       "  \"model_type\": \"phi3\",\n",
       "  \"num_attention_heads\": 40,\n",
       "  \"num_hidden_layers\": 40,\n",
       "  \"num_key_value_heads\": 10,\n",
       "  \"original_max_position_embeddings\": 4096,\n",
       "  \"pad_token_id\": 32000,\n",
       "  \"resid_pdrop\": 0.0,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"sliding_window\": 2047,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.44.0.dev0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32064\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea800031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ss] *",
   "language": "python",
   "name": "conda-env-ss-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
